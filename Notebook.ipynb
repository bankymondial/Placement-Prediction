{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78f190fe-8ae2-4a7e-8662-814cad1f83fd",
   "metadata": {},
   "source": [
    "## Placement Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a05aa3-a607-4bcf-b4f4-834d99ce8f5e",
   "metadata": {},
   "source": [
    "### 1. Data Preparation: Cleaning, Preprocessing & Exploratory Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cadcb54-6285-4797-824d-e9d3db024770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b25a3cd-8c8e-4d66-a139-a6c59421ebb3",
   "metadata": {},
   "source": [
    "#### Dataset is sourced from https://www.kaggle.com/datasets/ruchikakumbhar/placement-prediction-dataset/data?select=placementdata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d850588-daed-4ff8-ac03-696ec9403893",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = \"https://raw.githubusercontent.com/bankymondial/Placement-Prediction/refs/heads/main/placementdata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a864f8a0-209a-4951-b2bb-6f8299c3bc2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd4f5ebb-ef48-47c0-b6f3-4856dcb65b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   StudentID                  10000 non-null  int64  \n",
      " 1   CGPA                       10000 non-null  float64\n",
      " 2   Internships                10000 non-null  int64  \n",
      " 3   Projects                   10000 non-null  int64  \n",
      " 4   Workshops/Certifications   10000 non-null  int64  \n",
      " 5   AptitudeTestScore          10000 non-null  int64  \n",
      " 6   SoftSkillsRating           10000 non-null  float64\n",
      " 7   ExtracurricularActivities  10000 non-null  object \n",
      " 8   PlacementTraining          10000 non-null  object \n",
      " 9   SSC_Marks                  10000 non-null  int64  \n",
      " 10  HSC_Marks                  10000 non-null  int64  \n",
      " 11  PlacementStatus            10000 non-null  object \n",
      "dtypes: float64(2), int64(7), object(3)\n",
      "memory usage: 937.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13265ced-8a11-46cd-92b7-18674f51e373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentID</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Internships</th>\n",
       "      <th>Projects</th>\n",
       "      <th>Workshops/Certifications</th>\n",
       "      <th>AptitudeTestScore</th>\n",
       "      <th>SoftSkillsRating</th>\n",
       "      <th>ExtracurricularActivities</th>\n",
       "      <th>PlacementTraining</th>\n",
       "      <th>SSC_Marks</th>\n",
       "      <th>HSC_Marks</th>\n",
       "      <th>PlacementStatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>4.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>61</td>\n",
       "      <td>79</td>\n",
       "      <td>NotPlaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "      <td>Placed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>NotPlaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "      <td>Placed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "      <td>Placed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   StudentID  CGPA  Internships  Projects  Workshops/Certifications  \\\n",
       "0          1   7.5            1         1                         1   \n",
       "1          2   8.9            0         3                         2   \n",
       "2          3   7.3            1         2                         2   \n",
       "3          4   7.5            1         1                         2   \n",
       "4          5   8.3            1         2                         2   \n",
       "\n",
       "   AptitudeTestScore  SoftSkillsRating ExtracurricularActivities  \\\n",
       "0                 65               4.4                        No   \n",
       "1                 90               4.0                       Yes   \n",
       "2                 82               4.8                       Yes   \n",
       "3                 85               4.4                       Yes   \n",
       "4                 86               4.5                       Yes   \n",
       "\n",
       "  PlacementTraining  SSC_Marks  HSC_Marks PlacementStatus  \n",
       "0                No         61         79       NotPlaced  \n",
       "1               Yes         78         82          Placed  \n",
       "2                No         79         80       NotPlaced  \n",
       "3               Yes         81         80          Placed  \n",
       "4               Yes         74         88          Placed  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f54931c-b24b-4f1f-95f7-4123785a0162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         StudentID          CGPA   Internships      Projects  \\\n",
      "count  10000.00000  10000.000000  10000.000000  10000.000000   \n",
      "mean    5000.50000      7.698010      1.049200      2.026600   \n",
      "std     2886.89568      0.640131      0.665901      0.867968   \n",
      "min        1.00000      6.500000      0.000000      0.000000   \n",
      "25%     2500.75000      7.400000      1.000000      1.000000   \n",
      "50%     5000.50000      7.700000      1.000000      2.000000   \n",
      "75%     7500.25000      8.200000      1.000000      3.000000   \n",
      "max    10000.00000      9.100000      2.000000      3.000000   \n",
      "\n",
      "       Workshops/Certifications  AptitudeTestScore  SoftSkillsRating  \\\n",
      "count              10000.000000       10000.000000      10000.000000   \n",
      "mean                   1.013200          79.449900          4.323960   \n",
      "std                    0.904272           8.159997          0.411622   \n",
      "min                    0.000000          60.000000          3.000000   \n",
      "25%                    0.000000          73.000000          4.000000   \n",
      "50%                    1.000000          80.000000          4.400000   \n",
      "75%                    2.000000          87.000000          4.700000   \n",
      "max                    3.000000          90.000000          4.800000   \n",
      "\n",
      "          SSC_Marks     HSC_Marks  \n",
      "count  10000.000000  10000.000000  \n",
      "mean      69.159400     74.501500  \n",
      "std       10.430459      8.919527  \n",
      "min       55.000000     57.000000  \n",
      "25%       59.000000     67.000000  \n",
      "50%       70.000000     73.000000  \n",
      "75%       78.000000     83.000000  \n",
      "max       90.000000     88.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee7b254-9eba-4302-9795-a1e57c6f260b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "221abe53-7ffc-4af9-b63f-a7225ebc0016",
   "metadata": {},
   "source": [
    "#### This code changes modifies the column names, removing `/` and  changing all column names to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "361b5a65-bfde-4217-a86f-0c5fd5b12317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower().str.replace(' ', '_').str.replace('/', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "760e05ba-165d-41e8-90c2-fb0290f50de7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studentid</th>\n",
       "      <th>cgpa</th>\n",
       "      <th>internships</th>\n",
       "      <th>projects</th>\n",
       "      <th>workshopscertifications</th>\n",
       "      <th>aptitudetestscore</th>\n",
       "      <th>softskillsrating</th>\n",
       "      <th>extracurricularactivities</th>\n",
       "      <th>placementtraining</th>\n",
       "      <th>ssc_marks</th>\n",
       "      <th>hsc_marks</th>\n",
       "      <th>placementstatus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>3.9</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>NotPlaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "      <td>4.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>84</td>\n",
       "      <td>67</td>\n",
       "      <td>Placed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "      <td>Placed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>71</td>\n",
       "      <td>85</td>\n",
       "      <td>Placed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>8.4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>3.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>62</td>\n",
       "      <td>66</td>\n",
       "      <td>NotPlaced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      studentid  cgpa  internships  projects  workshopscertifications  \\\n",
       "9995       9996   7.5            1         1                        2   \n",
       "9996       9997   7.4            0         1                        0   \n",
       "9997       9998   8.4            1         3                        0   \n",
       "9998       9999   8.9            0         3                        2   \n",
       "9999      10000   8.4            0         1                        1   \n",
       "\n",
       "      aptitudetestscore  softskillsrating extracurricularactivities  \\\n",
       "9995                 72               3.9                       Yes   \n",
       "9996                 90               4.8                        No   \n",
       "9997                 70               4.8                       Yes   \n",
       "9998                 87               4.8                       Yes   \n",
       "9999                 66               3.8                        No   \n",
       "\n",
       "     placementtraining  ssc_marks  hsc_marks placementstatus  \n",
       "9995                No         85         66       NotPlaced  \n",
       "9996                No         84         67          Placed  \n",
       "9997               Yes         79         81          Placed  \n",
       "9998               Yes         71         85          Placed  \n",
       "9999                No         62         66       NotPlaced  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d6a581-72b3-40bb-894a-e761abfe7666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2171e9db-8328-401f-ac36-f365ad9ba63e",
   "metadata": {},
   "source": [
    "#### Data Preprocessing\n",
    "- Check for missing data\n",
    "- Encoding categorical features\n",
    "- Defining features (X) and target (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfbf7780-41ae-43de-b171-d8a395cb7ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studentid                    0\n",
       "cgpa                         0\n",
       "internships                  0\n",
       "projects                     0\n",
       "workshopscertifications      0\n",
       "aptitudetestscore            0\n",
       "softskillsrating             0\n",
       "extracurricularactivities    0\n",
       "placementtraining            0\n",
       "ssc_marks                    0\n",
       "hsc_marks                    0\n",
       "placementstatus              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfd8cee1-5df1-45a1-a086-42725484abbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "studentid                      int64\n",
       "cgpa                         float64\n",
       "internships                    int64\n",
       "projects                       int64\n",
       "workshopscertifications        int64\n",
       "aptitudetestscore              int64\n",
       "softskillsrating             float64\n",
       "extracurricularactivities     object\n",
       "placementtraining             object\n",
       "ssc_marks                      int64\n",
       "hsc_marks                      int64\n",
       "placementstatus               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c6ab22a-5066-4d25-b184-75ee614ff207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes']\n",
      "['No' 'Yes']\n",
      "['NotPlaced' 'Placed']\n"
     ]
    }
   ],
   "source": [
    "print(df['extracurricularactivities'].unique())\n",
    "print(df['placementtraining'].unique())\n",
    "print(df['placementstatus'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98bbda47-98a1-43f2-819f-9a0e476c6b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['extracurricularactivities'] = df['extracurricularactivities'].str.lower()\n",
    "df['placementtraining'] = df['placementtraining'].str.lower()\n",
    "df['placementstatus'] = df['placementstatus'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19686955-9862-4c85-ab2a-f5156e326670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['extracurricularactivities'] = df['extracurricularactivities'].map({'no': 0, 'yes': 1})\n",
    "df['placementtraining'] = df['placementtraining'].map({'no': 0, 'yes': 1})\n",
    "df['placementstatus'] = df['placementstatus'].map({'notplaced': 0, 'placed': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b643b14-d259-408a-b48f-f10f8c58ee39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "studentid                      int64\n",
      "cgpa                         float64\n",
      "internships                    int64\n",
      "projects                       int64\n",
      "workshopscertifications        int64\n",
      "aptitudetestscore              int64\n",
      "softskillsrating             float64\n",
      "extracurricularactivities      int64\n",
      "placementtraining              int64\n",
      "ssc_marks                      int64\n",
      "hsc_marks                      int64\n",
      "placementstatus                int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da3727d-06e2-4a08-b087-600d69143f55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1eeeed0-096c-4d9a-9c42-ba2450447c70",
   "metadata": {},
   "source": [
    "### 2.  Train-Validation-Test Split (60-20-20)\n",
    "- Define X (features) and y (target variable)\n",
    "- Split the data into train (60%) and temp (40%) for validation and test\n",
    "- Split the temp data into validation (50% of 40%) and test (50% of 40%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1b0a682-7712-4ea9-8a4b-90df9e0ff7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['studentid', 'placementstatus'])\n",
    "y = df['placementstatus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "805f55c2-f92c-4cd4-ab49-1282638541f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (6000, 10)\n",
      "Validation set shape: (2000, 10)\n",
      "Test set shape: (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape)\n",
    "print(\"Test set shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ecd9fb7-e6af-40ee-a8dc-a1d2a4945825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cgpa</th>\n",
       "      <th>internships</th>\n",
       "      <th>projects</th>\n",
       "      <th>workshopscertifications</th>\n",
       "      <th>aptitudetestscore</th>\n",
       "      <th>softskillsrating</th>\n",
       "      <th>extracurricularactivities</th>\n",
       "      <th>placementtraining</th>\n",
       "      <th>ssc_marks</th>\n",
       "      <th>hsc_marks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.9</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>90</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>85</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cgpa  internships  projects  workshopscertifications  aptitudetestscore  \\\n",
       "0   7.5            1         1                        1                 65   \n",
       "1   8.9            0         3                        2                 90   \n",
       "2   7.3            1         2                        2                 82   \n",
       "3   7.5            1         1                        2                 85   \n",
       "4   8.3            1         2                        2                 86   \n",
       "\n",
       "   softskillsrating  extracurricularactivities  placementtraining  ssc_marks  \\\n",
       "0               4.4                          0                  0         61   \n",
       "1               4.0                          1                  1         78   \n",
       "2               4.8                          1                  0         79   \n",
       "3               4.4                          1                  1         81   \n",
       "4               4.5                          1                  1         74   \n",
       "\n",
       "   hsc_marks  \n",
       "0         79  \n",
       "1         82  \n",
       "2         80  \n",
       "3         80  \n",
       "4         88  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6780ea-c009-48de-9230-33b57805c71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "55515578-9f29-4e14-b352-4bc85803be72",
   "metadata": {},
   "source": [
    "### 3. Normalizing Numerical Features\n",
    "- Normalization is needed for continuous features (like CGPA, Aptitude Test Score, Soft Skills Rating, SSC Marks, and HSC Marks) to ensure they don't dominate the model. This involves:\n",
    "  - Select numerical columns excluding categorical ones\n",
    "  - Initialize the scaler\n",
    "  - Fit on training data and transform train, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4c99718-3ebb-485c-be38-81951adbb25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "numerical_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "numerical_cols = numerical_cols.difference(['extracurricularactivities', 'placementtraining', 'placementstatus'])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_val[numerical_cols] = scaler.transform(X_val[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e7570-c0e6-4ea2-9823-163a50301bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "738aea8d-fec7-4d7c-acf6-3ec988cacd8e",
   "metadata": {},
   "source": [
    "### 4. Training Logistic Regression Model (Baseline Model)\n",
    "- Initialize and train the Logistic Regression Model\n",
    "- Predict on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88fc5b44-a34c-42b6-be7b-a764aefbb4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_val_pred = log_reg.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd118404-9299-42d1-bbbd-f5a8d41b40c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "371b2447-8323-4fb8-ad93-9736d222cec1",
   "metadata": {},
   "source": [
    "#### Evaluating Model Performance\n",
    "- Calculate metrics on validation set\n",
    "- Print evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d426178-cdda-4f55-8acd-347d974fa032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.7975\n",
      "Validation Precision: 0.7529\n",
      "Validation Recall: 0.7682\n",
      "Validation F1 Score: 0.7605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_val_pred)\n",
    "precision = precision_score(y_val, y_val_pred)\n",
    "recall = recall_score(y_val, y_val_pred)\n",
    "f1 = f1_score(y_val, y_val_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Validation Precision: {precision:.4f}\")\n",
    "print(f\"Validation Recall: {recall:.4f}\")\n",
    "print(f\"Validation F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585b2caf-e138-4150-99b4-812154b25467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9005161-874d-4ea1-968a-4c3eb49d866a",
   "metadata": {},
   "source": [
    "### 5. Feature Importance Analysis\n",
    "- Get feature importance from model coefficients\n",
    "- Sort by absolute value of coefficients\n",
    "- Display most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d29a383d-922d-4d8b-aa96-9126697608dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Feature  Coefficient\n",
      "7          placementtraining     0.955773\n",
      "6  extracurricularactivities     0.675994\n",
      "4          aptitudetestscore     0.554143\n",
      "9                  hsc_marks     0.343753\n",
      "5           softskillsrating     0.287111\n",
      "8                  ssc_marks     0.285684\n",
      "0                       cgpa     0.254303\n",
      "2                   projects     0.191061\n",
      "3    workshopscertifications     0.112340\n",
      "1                internships     0.017232\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_train.columns,\n",
    "    'Coefficient': log_reg.coef_[0]\n",
    "})\n",
    "\n",
    "feature_importance['Abs_Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "feature_importance = feature_importance.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "print(feature_importance[['Feature', 'Coefficient']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fa32ee-270c-4475-9095-6ad41610ad57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd16e63-7c5f-441a-aafb-385de3e16085",
   "metadata": {},
   "source": [
    "### 6. Evaluation on Test set\n",
    "- Predict on test set\n",
    "- Compute test metrics\n",
    "- Print final test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3126ca3-0525-4bc4-8f68-e6ef6d60d4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7855\n",
      "Test Precision: 0.7426\n",
      "Test Recall: 0.7452\n",
      "Test F1 Score: 0.7439\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = log_reg.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_f1 = f1_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03dd881-93c6-4e15-b702-113929156ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22c129e6-125c-4fbf-ae58-e0e20c8cd7c9",
   "metadata": {},
   "source": [
    "#### Model Performance Analysis\n",
    "\n",
    "- Validation vs. Test Performance: The test accuracy (0.7855) is slightly lower than validation accuracy (0.7975), meaning the model generalizes well but might be slightly overfitting.  \n",
    "- Precision & Recall Tradeoff: Precision (0.7529) is slightly lower than recall (0.7682), meaning the model misclassifies some placed students as not placed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d488af72-41c5-423b-a3c5-a492ee330ef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2975f2-7e66-40d3-80b5-2d9e5a232051",
   "metadata": {},
   "source": [
    "###  7. Finding the optimal threshold to find a balance between precision and recall (i.e., for both classes — \"Placed\" and \"Not Placed\") or select the threshold that maximizes F1 score.\n",
    "- Get the predicted probabilities for the positive class\n",
    "- Compute precision, recall, and threshold\n",
    "- Calculate F1 score for each threshold\n",
    "- Find the threshold with the highest F1 score\n",
    "- Apply the optimal threshold to make predictions\n",
    "- Evaluate performance with the new threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a231bce-f4cc-4c7b-b179-75bbcad3fc8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.4152416296778436\n",
      "Test Precision: 0.7213822894168467\n",
      "Test Recall: 0.7990430622009569\n",
      "Test F1 Score: 0.7582292849035187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "y_prob = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "\n",
    "y_pred_optimal = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "precision_optimal = precision_score(y_test, y_pred_optimal)\n",
    "recall_optimal = recall_score(y_test, y_pred_optimal)\n",
    "f1_optimal = f1_score(y_test, y_pred_optimal)\n",
    "\n",
    "print(f\"Test Precision: {precision_optimal}\")\n",
    "print(f\"Test Recall: {recall_optimal}\")\n",
    "print(f\"Test F1 Score: {f1_optimal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f55cfdb-7f87-45fe-b06b-29dc756287b8",
   "metadata": {},
   "source": [
    "#### Baseline Model: The threshold of 0.4152 seems to provide a nice balance between precision and recall, with a solid F1 score of approximately 0.7582. This threshold suggests that the model is effectively identifying students who are likely to be placed while maintaining a good level of precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a16eae-b6e7-48ca-85fd-eab52352e8d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e64eaa5-14f3-48d6-a797-cbfcc8878490",
   "metadata": {},
   "source": [
    "### 8. Building a model using the most important features based on the `feature importance analysis`, a simplified dataset\n",
    "- Select the most important features based on the feature importance analysis\n",
    "- Update the features to include only the selected ones\n",
    "- Train the logistic regression model with selected features\n",
    "- Evaluate the model on validation data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca3e2894-c1d4-4947-ab60-1c9d985583fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "important_features = [\n",
    "    'placementtraining', 'extracurricularactivities', 'aptitudetestscore', \n",
    "    'hsc_marks', 'softskillsrating'\n",
    "]\n",
    "\n",
    "X_train_important = X_train[important_features]\n",
    "X_val_important = X_val[important_features]\n",
    "X_test_important = X_test[important_features]\n",
    "\n",
    "log_reg_important = LogisticRegression(random_state=42)\n",
    "log_reg_important.fit(X_train_important, y_train)\n",
    "\n",
    "y_val_pred_important = log_reg_important.predict(X_val_important)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bec712a-c5d4-48e4-b114-1145f73c2b5f",
   "metadata": {},
   "source": [
    "### \n",
    "- Evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ac3cfc9-9343-4cc8-ba16-91d53ecb452a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Precision (Important Features): 0.7426210153482881\n",
      "Validation Recall (Important Features): 0.7514934289127837\n",
      "Validation F1 Score (Important Features): 0.7470308788598575\n"
     ]
    }
   ],
   "source": [
    "precision_important = precision_score(y_val, y_val_pred_important)\n",
    "recall_important = recall_score(y_val, y_val_pred_important)\n",
    "f1_important = f1_score(y_val, y_val_pred_important)\n",
    "\n",
    "print(\"Validation Precision (Important Features):\", precision_important)\n",
    "print(\"Validation Recall (Important Features):\", recall_important)\n",
    "print(\"Validation F1 Score (Important Features):\", f1_important)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5d332d-d71f-42fe-b07a-423975249fd6",
   "metadata": {},
   "source": [
    "###\n",
    "- Test the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43c22943-f457-4869-a28e-653bccc1d304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Precision (Important Features): 0.7394451145958987\n",
      "Test Recall (Important Features): 0.7332535885167464\n",
      "Test F1 Score (Important Features): 0.7363363363363363\n"
     ]
    }
   ],
   "source": [
    "y_test_pred_important = log_reg_important.predict(X_test_important)\n",
    "\n",
    "precision_test_important = precision_score(y_test, y_test_pred_important)\n",
    "recall_test_important = recall_score(y_test, y_test_pred_important)\n",
    "f1_test_important = f1_score(y_test, y_test_pred_important)\n",
    "\n",
    "print(\"Test Precision (Important Features):\", precision_test_important)\n",
    "print(\"Test Recall (Important Features):\", recall_test_important)\n",
    "print(\"Test F1 Score (Important Features):\", f1_test_important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fcc092-3590-49cc-baa0-d845e69d8255",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08bd3ad3-908c-4254-99a8-837e08f59c99",
   "metadata": {},
   "source": [
    "### 8b. Adjusting the threshold and Recomputing Metrics\n",
    "- This method should help optimize the model's classification performance for the placement prediction task, since the goal is to have a better balance between both classes (placed and not placed).\n",
    "  - Get predicted probabilities for the positive class (placement)\n",
    "  - Calculate precision, recall, and thresholds\n",
    "  - Calculate F1 scores for each threshold\n",
    "  - Find the threshold that maximizes the F1 score\n",
    "  - Reclassify the test set using the optimal threshold\n",
    "  - Evaluate the model with the optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4ca0686-739f-4eda-ba83-706d69b392fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.4152416296778436\n",
      "Test Precision (Optimal Threshold): 0.7213822894168467\n",
      "Test Recall (Optimal Threshold): 0.7990430622009569\n",
      "Test F1 Score (Optimal Threshold): 0.7582292849035187\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "\n",
    "y_prob = log_reg.predict_proba(X_test)[:, 1]\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "optimal_threshold = thresholds[f1_scores.argmax()]\n",
    "\n",
    "y_test_pred_optimal = (y_prob >= optimal_threshold).astype(int)\n",
    "\n",
    "test_precision_optimal = precision_score(y_test, y_test_pred_optimal)\n",
    "test_recall_optimal = recall_score(y_test, y_test_pred_optimal)\n",
    "test_f1_optimal = f1_score(y_test, y_test_pred_optimal)\n",
    "\n",
    "print(f\"Optimal Threshold: {optimal_threshold}\")\n",
    "print(f\"Test Precision (Optimal Threshold): {test_precision_optimal}\")\n",
    "print(f\"Test Recall (Optimal Threshold): {test_recall_optimal}\")\n",
    "print(f\"Test F1 Score (Optimal Threshold): {test_f1_optimal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3af7a4-13d3-43be-9868-a9e2fdedc46d",
   "metadata": {},
   "source": [
    "#### Despite the difference in feature selection, the optimal threshold for classification hasn't changed, and the resulting performance metrics (precision, recall, and F1 score) are similar.  While the number of features has been reduced, it seems that the core relationships in the data that drive placement predictions may not be drastically different, as the model's performance metrics remain consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c35d6a-3d18-4a57-975f-e61e7c54466e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a448513-4487-42f3-805f-e66db4c17ed9",
   "metadata": {},
   "source": [
    "### 9. Performing further tests analyze the impact of feature selection and evaluate the effectiveness of using important features\n",
    "- Comparing Training Time between baseline model and important features model\n",
    "  - Measure training time for baseline model\n",
    "  - Measure training time for important features model\n",
    "- Comparing Cross Validation Scores between baseline model and important features model\n",
    "  - Cross-validation for baseline model\n",
    "  - Cross-validation for important features model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6b0ad803-d70e-49af-b4f3-8bdd8cbfe68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Training Time: 0.0079 seconds\n",
      "Important Features Model Training Time: 0.0050 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "log_reg.fit(X_train, y_train)\n",
    "baseline_training_time = time.time() - start_time\n",
    "\n",
    "start_time = time.time()\n",
    "log_reg.fit(X_train_important, y_train)\n",
    "important_features_training_time = time.time() - start_time\n",
    "\n",
    "print(f\"Baseline Model Training Time: {baseline_training_time:.4f} seconds\")\n",
    "print(f\"Important Features Model Training Time: {important_features_training_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7281902-4ef7-4035-85ae-ea3f2efb1e5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac197ccd-8824-474a-bb55-111f234421d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Cross-validation F1 Scores: [0.77475728 0.74441205 0.77091633 0.79919679 0.76      ]\n",
      "Important Features Model Cross-validation F1 Scores: [0.76246334 0.73724735 0.772      0.77822581 0.74801587]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "baseline_cv_score = cross_val_score(log_reg, X_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "important_features_cv_score = cross_val_score(log_reg, X_train_important, y_train, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"Baseline Model Cross-validation F1 Scores: {baseline_cv_score}\")\n",
    "print(f\"Important Features Model Cross-validation F1 Scores: {important_features_cv_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde28ca9-ca77-4f78-900a-1b589e5c4e5d",
   "metadata": {},
   "source": [
    "### Conclusion 1\n",
    "- The model with important features is faster to train, which can lead to better scalability, especially as the dataset grows. This could be crucial in real-world scenarios where time efficiency is critical (e.g., in deployment or real-time systems).\n",
    "- The Baseline model has slightly higher F1 scores on average than F1 scores of the important features model, meaning it’s capturing both precision and recall better overall.\n",
    "- The drop in F1 score for the important features model is not drastic, indicating that the feature selection process still yields a model that performs fairly well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1312034-cd35-43f6-a3e6-2aa37c815da7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a4533ff2-3aef-4c8b-9ea6-3f2378168f37",
   "metadata": {},
   "source": [
    "### 10. Training other model for comparison to the Important Features Model before making a final choice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3606a208-6e1d-473d-9f1d-35cc3b5ecd9a",
   "metadata": {},
   "source": [
    "#### 10a. Train Random Forest Model\n",
    "- Initialize and train the Random Forest model\n",
    "- Predict probabilities and apply the optimal threshold\n",
    "- Evaluate with default 0.5 threshold\n",
    "- Compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78023043-333d-44af-84de-a4f51259b586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Validation Precision: 0.7399\n",
      "Random Forest - Validation Recall: 0.7037\n",
      "Random Forest - Validation F1 Score: 0.7214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_prob_rf = rf_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "y_val_pred_rf = (y_val_prob_rf >= 0.5).astype(int)\n",
    "\n",
    "rf_precision = precision_score(y_val, y_val_pred_rf)\n",
    "rf_recall = recall_score(y_val, y_val_pred_rf)\n",
    "rf_f1 = f1_score(y_val, y_val_pred_rf)\n",
    "\n",
    "print(f\"Random Forest - Validation Precision: {rf_precision:.4f}\")\n",
    "print(f\"Random Forest - Validation Recall: {rf_recall:.4f}\")\n",
    "print(f\"Random Forest - Validation F1 Score: {rf_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eed671d-114e-4238-a60d-18aab1b26ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c3da286-d980-46ff-9fa0-a3404abcb754",
   "metadata": {},
   "source": [
    "### 10b. Train XGBoost Model\n",
    "- Initialize and train the XGBoost model\n",
    "- Predict probabilities and apply the optimal threshold\n",
    "- Evaluate with default 0.5 threshold\n",
    "- Compute evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cb5a070-8225-4ddc-ac6e-0f4d4df2e590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/python/3.12.1/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy in /home/codespace/.local/lib/python3.12/site-packages (from xgboost) (2.2.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/python/3.12.1/lib/python3.12/site-packages (from xgboost) (2.25.1)\n",
      "Requirement already satisfied: scipy in /home/codespace/.local/lib/python3.12/site-packages (from xgboost) (1.14.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "XGBoost - Validation Precision: 0.7332\n",
      "XGBoost - Validation Recall: 0.7025\n",
      "XGBoost - Validation F1 Score: 0.7175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:34:22] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\", random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_val_prob_xgb = xgb_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "y_val_pred_xgb = (y_val_prob_xgb >= 0.5).astype(int)\n",
    "\n",
    "xgb_precision = precision_score(y_val, y_val_pred_xgb)\n",
    "xgb_recall = recall_score(y_val, y_val_pred_xgb)\n",
    "xgb_f1 = f1_score(y_val, y_val_pred_xgb)\n",
    "\n",
    "print(f\"XGBoost - Validation Precision: {xgb_precision:.4f}\")\n",
    "print(f\"XGBoost - Validation Recall: {xgb_recall:.4f}\")\n",
    "print(f\"XGBoost - Validation F1 Score: {xgb_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0523cd-ab68-4547-86c7-0e3b788f49a2",
   "metadata": {},
   "source": [
    "### Conclusion 2: Both Random Forest and XGBoost are performing slightly worse than the logistic regression model with important features in terms of validation F1 score:\n",
    "\n",
    "Logistic Regression (Important Features): F1 = 0.7470  \n",
    "Random Forest: F1 = 0.7214  \n",
    "XGBoost: F1 = 0.7175  \n",
    "This suggests that the logistic regression model with important features is not only simpler but also more effective for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e38caf-2337-4f96-816d-ccd73436e19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e772ea9-73af-424b-902a-d913ed4b5ecf",
   "metadata": {},
   "source": [
    "#### 10c. Evaluating both models on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a345586-bd8f-4359-a5fc-5572598a91af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest - Test Precision: 0.7519\n",
      "Random Forest - Test Recall: 0.7069\n",
      "Random Forest - Test F1 Score: 0.7287\n",
      "----------------------------------------\n",
      "XGBoost - Test Precision: 0.7357\n",
      "XGBoost - Test Recall: 0.7057\n",
      "XGBoost - Test F1 Score: 0.7204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Predictions for Random Forest\n",
    "y_test_pred_rf = rf_model.predict(X_test)\n",
    "rf_precision = precision_score(y_test, y_test_pred_rf)\n",
    "rf_recall = recall_score(y_test, y_test_pred_rf)\n",
    "rf_f1 = f1_score(y_test, y_test_pred_rf)\n",
    "\n",
    "# Predictions for XGBoost\n",
    "y_test_pred_xgb = xgb_model.predict(X_test)\n",
    "xgb_precision = precision_score(y_test, y_test_pred_xgb)\n",
    "xgb_recall = recall_score(y_test, y_test_pred_xgb)\n",
    "xgb_f1 = f1_score(y_test, y_test_pred_xgb)\n",
    "\n",
    "# Display results\n",
    "print(f\"Random Forest - Test Precision: {rf_precision:.4f}\")\n",
    "print(f\"Random Forest - Test Recall: {rf_recall:.4f}\")\n",
    "print(f\"Random Forest - Test F1 Score: {rf_f1:.4f}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"XGBoost - Test Precision: {xgb_precision:.4f}\")\n",
    "print(f\"XGBoost - Test Recall: {xgb_recall:.4f}\")\n",
    "print(f\"XGBoost - Test F1 Score: {xgb_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7048dab0-542a-4b9a-a8b7-a87146e1b0b2",
   "metadata": {},
   "source": [
    "### Conclusion 3: As expected, both Random Forest and XGBoost have lower test F1 scores compared to the Logistic Regression (Important Features) model.\n",
    "- Important Features Model (Logistic Regression, Optimal Threshold): 0.7582\n",
    "- Random Forest: 0.7287\n",
    "- XGBoost: 0.7204"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d37f25-de69-49aa-a005-592ff25ea317",
   "metadata": {},
   "source": [
    "### Takeaways:\n",
    "- Random Forest and XGBoost did not outperform the Logistic Regression model.\n",
    "- Logistic Regression (Important Features) remains the best choice because it’s simpler, trains faster, and achieves the best balance of precision and recall.\n",
    "- If interpretability matters, logistic regression is the clear winner since it's easy to explain, while tree-based models like Random Forest and XGBoost are more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56eb7ac4-aeeb-476b-b7d7-aefec82b0add",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
